{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3e0168-8609-43c7-b91e-7b5dbc3cb627",
   "metadata": {},
   "source": [
    "# AutoML Benchmarking: AutoGluon, AutoSklearn, and MLSea (AssistML)\n",
    "\n",
    "This notebook provides a comparative evaluation of three state-of-the-art AutoML frameworks: **AutoGluon**, **AutoSklearn** and **MLSea (AssistML)**.  \n",
    "The goal is to assess their performance and usability on a unified dataset, using a consistent experimental setup.  \n",
    "\n",
    "The notebook is designed to accompany the corresponding scientific publication and includes code, preprocessing steps, and evaluation procedures that ensure full reproducibility of the experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8869cb3-22dd-49fa-b270-60d5c53d4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = './tmp/data/pda_2023-04-18_10-13-22.csv'\n",
    "label_location = './tmp/data/labels_030723.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2eaa1ce-6966-4d63-8d9a-caf8ea5f26e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 14098  100 14098    0     0  27737      0 --:--:-- --:--:-- --:--:-- 27697\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 67.7M  100 67.7M    0     0  57.3M      0  0:00:01  0:00:01 --:--:-- 57.3M\n"
     ]
    }
   ],
   "source": [
    "!curl --create-dirs -O --output-dir \\\n",
    "./tmp/data \\\n",
    "https://gitlab.com/mibbels/automlwrapperdata/-/raw/main/tabular-regression/labels_030723.csv \n",
    "\n",
    "!curl --create-dirs -O --output-dir \\\n",
    "./tmp/data \\\n",
    "https://gitlab.com/mibbels/automlwrapperdata/-/raw/main/tabular-regression/pda_2023-04-18_10-13-22.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d47ad-7103-4fda-84ef-f6d00cc22924",
   "metadata": {},
   "source": [
    "# data preparation taken without changes \n",
    "Hoseini, S., et. al.: Coatings intelligence: Data-driven automation for chemistry\n",
    "4.0. In: 2024 IEEE 7th (ICPS). pp. 1â€“8 (2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9064e7-6274-4e28-b5c8-aaa245612499",
   "metadata": {},
   "source": [
    "This transformation involves:\n",
    "1. Extracting selected features (e.g., `x_force`, `y_force`, `z_force`).\n",
    "2. Padding sequences to ensure consistent dimensionality.\n",
    "3. Splitting the dataset into **training**, **validation**, and **test sets**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408011d2-f867-48ca-a708-c82d5b134901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n",
      "398\n",
      "398\n",
      "398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_423351/240422575.py:88: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  row_value = int(indidvidual['row'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{519}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "csv = pd.read_csv(data_location, skiprows = 0)\n",
    "csv['Zeit'] =  pd.to_datetime(csv['Zeit'])\n",
    "csv.sort_values(by='Zeit', inplace = True)\n",
    "\n",
    "TIME_LIMIT = 60 * 60\n",
    "\n",
    "labels = pd.read_csv(label_location)\n",
    "labels = labels[labels['row'] != 'None']\n",
    "labels = labels[labels['row'] != 'Aussortieren']\n",
    "print(len(labels))\n",
    "\n",
    "df = csv[['Zeit','product_id', 'run_id', 'experiment_id', 'trial_id', 'set_force_begin',\n",
    "       'x_position', 'y_position', 'z1_position', 'z2_position', 'x_velocity',\n",
    "       'y_velocity', 'z1_velocity', 'z2_velocity', 'x_force', 'y_force',\n",
    "       'z_force']]\n",
    "df = df[df[\"product_id\"] == 304]\n",
    "good_experiment_ids = [{\"run_id\": 0, \"experiment_ids\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
    "                  {\"run_id\": 1, \"experiment_ids\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
    "                  {\"run_id\": 2, \"experiment_ids\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
    "                  {\"run_id\": 3, \"experiment_ids\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
    "                ]\n",
    "peak_dfs = []\n",
    "i = 0\n",
    "for item in good_experiment_ids:\n",
    "    df_temp = df[df[\"run_id\"] == item[\"run_id\"]]\n",
    "    for item2 in item[\"experiment_ids\"]:\n",
    "        df_temp2 = df_temp[df_temp[\"experiment_id\"] == item2]\n",
    "        liste_temp = df_temp2[\"trial_id\"].unique()\n",
    "        for item3 in liste_temp:\n",
    "            i += 1\n",
    "            #print(item[\"run_id\"], item2, item3 )\n",
    "            if labels[(labels['trial_id'] == item3) & (labels['experiment_id'] == item2) & (labels['run_id'] == item[\"run_id\"])].shape[0] > 0:\n",
    "                peak_df = df_temp2[df_temp2[\"trial_id\"] == item3]\n",
    "                peak_dfs.append(peak_df[[\"run_id\", \"trial_id\", \"experiment_id\", 'x_position', 'x_force', 'y_force', 'z_force']])\n",
    "                \n",
    "print(len(peak_dfs))\n",
    "\n",
    "filtered_peak_dfs = []\n",
    "\n",
    "for i, item in enumerate(peak_dfs):\n",
    "    filtered_df_temp = item[item['x_position'] > 20.0001].reset_index(drop=True)\n",
    "    \n",
    "    peak_row_temp = filtered_df_temp['x_position'].idxmax()\n",
    "    \n",
    "    peak_row_data_temp = filtered_df_temp.loc[:peak_row_temp-1]\n",
    "    \n",
    "    filtered_df_temp2 = filtered_df_temp.loc[peak_row_temp:]\n",
    "    \n",
    "    condition = filtered_df_temp2['x_force'] >= 0\n",
    "    \n",
    "    extracted_rows = filtered_df_temp2.loc[:condition.idxmax()]\n",
    "        \n",
    "    if (extracted_rows['x_position'] >= 99.9).all():\n",
    "        filtered_peak_dfs.append(pd.concat([peak_row_data_temp, extracted_rows]))\n",
    "    else:\n",
    "        filtered_peak_dfs.append(peak_row_data_temp)\n",
    "print(len(filtered_peak_dfs))\n",
    "\n",
    "max_length = max(len(df) for df in filtered_peak_dfs)\n",
    "\n",
    "padded_dataframes = []\n",
    "for df in filtered_peak_dfs:\n",
    "    padding_size = 519 - len(df) #padding_size - len(df) # check classification\n",
    "    padded_df = pd.DataFrame(np.pad(df.values, ((0, padding_size), (0, 0)), mode='edge'), columns=df.columns)\n",
    "    padded_df['index'] = padded_df.index\n",
    "    padded_dataframes.append(padded_df)\n",
    "print(len(padded_dataframes))\n",
    "\n",
    "lengths = set()\n",
    "polke_padded_dataframes_with_labels = []\n",
    "for item in padded_dataframes:\n",
    "    lengths.add(len(item))\n",
    "    \n",
    "    run_id = item[\"run_id\"].unique()[0],\n",
    "    trial_id = item[\"trial_id\"].unique()[0],\n",
    "    experiment_id = item[\"experiment_id\"].unique()[0]\n",
    "    \n",
    "    #print(\"RUN_ID:\", run_id,\"experiment_id:\",  experiment_id,\"trial_id:\", trial_id)\n",
    "\n",
    "    indidvidual = labels[labels[\"run_id\"] == run_id]\n",
    "    indidvidual = indidvidual[indidvidual[\"experiment_id\"] == experiment_id]\n",
    "    indidvidual = indidvidual[indidvidual[\"trial_id\"] == trial_id]\n",
    "    \n",
    "    try:\n",
    "        if indidvidual['row'].iloc[0].isnumeric():\n",
    "            row_value = int(indidvidual['row'])\n",
    "            polke_padded_dataframes_with_labels.append((item, row_value))\n",
    "        else:\n",
    "            continue                                       ### <<<----- added try block\n",
    "    except AttributeError as a:\n",
    "        continue\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e609ee-b042-4c5d-9fcc-b575cd3de555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/autosklearn-env39/lib/python3.9/site-packages/sklearn/utils/fixes.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "padded_dataframes_with_labels_combined = polke_padded_dataframes_with_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6fdab-37d8-4baf-92c6-65866474cf92",
   "metadata": {},
   "source": [
    "## Exporting Processed Data\n",
    "\n",
    "For transparency and reproducibility, the labeled dataframe is exported as CSV file.  \n",
    "This step ensures that all tested frameworks operate on the exact same data representation as pipelines are implemented differently across frameworks.  \n",
    "\n",
    "This CSV file serves as the standardized input format for the subsequent LLM-based experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a218e7-e764-437b-8fc6-52718d85aa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to ./tmp/transformed_data/scratchtest_transformed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for df, label in padded_dataframes_with_labels_combined:\n",
    "    temp = df.copy()\n",
    "    temp['label'] = label\n",
    "    rows.append(temp)\n",
    "\n",
    "final_df = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# Exportiere als CSV\n",
    "final_df.to_csv(\"./tmp/transformed_data/scratchtest_transformed.csv\", index=False)\n",
    "print(\"Exported to ./tmp/transformed_data/scratchtest_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30d0b62-341f-4760-952a-93af689948d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "255\n",
      "(204, 519, 1) (41, 519, 1) (204,) (41,) (10, 519, 1) (10,)\n"
     ]
    }
   ],
   "source": [
    "tensor_X = []\n",
    "tensor_y = []\n",
    "for item in padded_dataframes_with_labels_combined:\n",
    "    #df_temp = item[0][['x_force', 'y_force', 'z_force']].copy()\n",
    "    #df_temp = item[0][['x_force', 'z_force']].copy()\n",
    "    df_temp = item[0][['x_force']].copy()\n",
    "    a = df_temp.to_numpy().astype(np.float32)\n",
    "    tensor_X.append(a)\n",
    "    tensor_y.append(item[1])\n",
    "print(len(tensor_X))\n",
    "print(len(tensor_y))\n",
    "\n",
    "# train test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(np.array(tensor_X), np.array(tensor_y), test_size=0.2, shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.8, shuffle=True)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_val.shape , y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04b8690-45bf-427c-b67b-991c1014af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(X_train.reshape(X_train.shape[:2]))\n",
    "train['label'] = y_train\n",
    "\n",
    "test = pd.DataFrame(X_test.reshape(X_test.shape[:2]))\n",
    "test['label'] = y_test \n",
    "\n",
    "val = pd.DataFrame(X_val.reshape(X_val.shape[:2]))\n",
    "val['label'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c1b19a-4125-4f4c-af42-9de5955e05b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204, 520)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d766a76a-ff24-4fac-917c-70a740362ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 520)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35234543-80f3-4136-bf5f-55ffe706fa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 520)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81e441-1c19-4722-9813-d7330357b53c",
   "metadata": {},
   "source": [
    "# Optimizing a range of different predictors using AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26fc4560-0cd3-4833-96cd-f230f5393ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 Î¼s, sys: 0 ns, total: 36 Î¼s\n",
      "Wall time: 56.3 Î¼s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from automlwrapper import AutoMLWrapper\n",
    "import sedarapi\n",
    "\n",
    "def wrapper_medium(train_data,val_data, eval_metric):\n",
    "    \n",
    "    wrapper = AutoMLWrapper('autogluon')\n",
    "    wrapper.Train(\n",
    "        train_data=train_data,\n",
    "        validation_data=val_data,\n",
    "        target_column='label',\n",
    "        task_type='regression',\n",
    "        data_type='tabular',\n",
    "        problem_type='regression',\n",
    "        hyperparameters={'time_limit': TIME_LIMIT,\n",
    "                         'preset' : 'medium_quality',\n",
    "                        'eval_metric':eval_metric},\n",
    "    )\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df2c485d-ef90-4944-ab25-abf8aaf5fbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"/home/jovyan/vhermann/AutoMLOutput/autogluon1758883405.581418\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #236-Ubuntu SMP Fri Apr 11 19:53:21 UTC 2025\n",
      "CPU Count:          104\n",
      "Memory Avail:       718.20 GB / 754.52 GB (95.2%)\n",
      "Disk Space Avail:   1073.42 GB / 3665.44 GB (29.3%)\n",
      "===================================================\n",
      "Train Data Rows:    204\n",
      "Train Data Columns: 519\n",
      "Tuning Data Rows:    10\n",
      "Tuning Data Columns: 519\n",
      "Label Column:       label\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    735438.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.42 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 7): ['512', '513', '514', '515', '516', '517', '518']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 7 | ['512', '513', '514', '515', '516', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 512 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 512 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t512 features in original data used to generate 512 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.42 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.48s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Warning: use_bag_holdout=True, but bagged mode is not enabled. use_bag_holdout will be ignored.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.52s of the 3599.51s of remaining time.\n",
      "\t-539.852\t = Validation score   (-mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.27s of the 3599.26s of remaining time.\n",
      "\t-444.8339\t = Validation score   (-mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3599.13s of the 3599.12s of remaining time.\n",
      "\t-168.6455\t = Validation score   (-mean_squared_error)\n",
      "\t1.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3597.72s of the 3597.72s of remaining time.\n",
      "\t-594.7347\t = Validation score   (-mean_squared_error)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3596.82s of the 3596.81s of remaining time.\n",
      "\t-1307.095\t = Validation score   (-mean_squared_error)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3595.6s of the 3595.6s of remaining time.\n",
      "\t-293.7042\t = Validation score   (-mean_squared_error)\n",
      "\t4.99s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3590.58s of the 3590.58s of remaining time.\n",
      "\t-186.5584\t = Validation score   (-mean_squared_error)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3589.43s of the 3589.42s of remaining time.\n",
      "\t-710.7414\t = Validation score   (-mean_squared_error)\n",
      "\t3.17s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3586.22s of the 3586.21s of remaining time.\n",
      "\t-3630.1458\t = Validation score   (-mean_squared_error)\n",
      "\t2.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3584.12s of the 3584.11s of remaining time.\n",
      "\t-141.926\t = Validation score   (-mean_squared_error)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3581.85s of the 3581.85s of remaining time.\n",
      "\t-2789.4818\t = Validation score   (-mean_squared_error)\n",
      "\t2.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3579.67s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.577, 'KNeighborsDist': 0.269, 'LightGBMXT': 0.154}\n",
      "\t-30.2416\t = Validation score   (-mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.7s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/jovyan/vhermann/AutoMLOutput/autogluon1758883405.581418\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 22s, sys: 15.2 s, total: 10min 37s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w = wrapper_medium(train, val, 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e50736e7-ef63-45ad-8f8e-0fc804d7f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_squared_error': -154.76163652268517, 'root_mean_squared_error': -12.44032300716847, 'mean_absolute_error': -9.286921245295828, 'r2': 0.9852065189753383, 'pearsonr': 0.9929851051167379, 'median_absolute_error': -6.12017822265625}\n",
      "CPU times: user 2.34 s, sys: 61.5 ms, total: 2.4 s\n",
      "Wall time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "extra_kwargs_for_auto_gluon = {'auxiliary_metrics' : True, 'detailed_report' : True}\n",
    "\n",
    "re = w.Evaluate(test, target_column='Type', **extra_kwargs_for_auto_gluon)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a197f-5224-4c40-848d-6e355353d06d",
   "metadata": {},
   "source": [
    "# Optimizing a range of different predictors using AutoSklearn\n",
    "\n",
    "### kernel needs to be changed from 'automl' to 'AutoSklearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d547745-0c84-4f4e-83e2-e1f3ab3498e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosklearn.regression import AutoSklearnRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c62c506-d3d4-47cf-aa08-be81f34318a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING AutoGluon could not be mported. It might not b available in this environment. Err: \n",
      " No module named 'autogluon'.\n",
      "WARNING AutoKeras could not be imported. It might not be available in this environment. Err: \n",
      " No module named 'autokeras'.\n",
      "WARNING: PySpark not installed. Some functionalities might not be available.\n",
      "WARNING: pywebhdfs not installed. Some functionalities might not be available.\n"
     ]
    }
   ],
   "source": [
    "from automlwrapper import AutoMLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2821540-e3ac-4caa-b687-3e2bf7394c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Code\n",
    "def wrapper_sk(train_data):\n",
    "    \n",
    "    wrapper = AutoMLWrapper('autosklearn')\n",
    "    wrapper.Train(\n",
    "        train_data=train_data,\n",
    "        target_column='label',\n",
    "        task_type='regression',\n",
    "        data_type='tabular',\n",
    "        problem_type='regression',\n",
    "        hyperparameters={'time_limit': 3600, \n",
    "                         'memory_limit': 102400,\n",
    "            'evaluation_metric':'mean_absolute_error'\n",
    "                        }\n",
    "    )\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b316bb46-36f8-43f4-b46e-bcac76dc77de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoSklearn\n",
      "CPU times: user 6min 34s, sys: 10.2 s, total: 6min 44s\n",
      "Wall time: 59min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"AutoSklearn\")\n",
    "w = wrapper_sk(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cad04dc-1e51-456b-8c9e-e0e03a2e7420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.39143378560136\n",
      "CPU times: user 119 ms, sys: 50 Âµs, total: 119 ms\n",
      "Wall time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ev = w.Evaluate(test, target_column='label',detailed_report=True)\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd514b3-ef9c-46e5-a7d0-9c3f68ac421e",
   "metadata": {},
   "source": [
    "-------------\n",
    "# Evaluating the capability of GPT-4o when creating regression code\n",
    "\n",
    "To complement the direct execution of AutoML frameworks, we additionally evaluate the capability of large language models (LLMs) to translate AssistML recommendations into executable code. \n",
    "\n",
    "For this purpose, we selected the top-ranked configuration suggested by the AssistML dashboard for the dataset *scratchtest_transformed.csv*. \n",
    "\n",
    "The dashboard output contained a structured report with model families, hyperparameters, and preprocessing steps, which we used as the basis for generating natural language prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9447ee00-af18-4079-b3c3-3239f46318ac",
   "metadata": {},
   "source": [
    "__AssistML Recommendation (Top-ranked)__\n",
    "\n",
    "![AssistML Recommendation top-ranked](./images/assistmloutput1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb63f23-3ab2-4e52-a296-9c349b45b69a",
   "metadata": {},
   "source": [
    "__AssistML Recommendation (Second-ranked)__\n",
    "\n",
    "![AssistML Recommendation second-ranked](./images/assistmloutput2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf52e36-b3af-4cd8-8b98-ea30bc911af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=sk..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc3a07a-bf43-4e20-9420-d61fdc634ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b46ba3c9-bf2a-4cc3-974f-bdd3f4552fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Import necessary libraries\n",
       "import pandas as pd\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
       "from dabl import preprocessing, models\n",
       "from sklearn.pipeline import Pipeline\n",
       "from time import time\n",
       "\n",
       "# Load the dataset\n",
       "data = pd.read_csv('scratchtest_transformed.csv')\n",
       "\n",
       "# Split the data into features and target variable\n",
       "X = data.drop(['label'], axis=1)\n",
       "y = data['label']\n",
       "\n",
       "# Split data into training and test sets\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
       "\n",
       "# Create the pipeline consisting of EasyPreprocessor and Simple Regressor\n",
       "pipeline = Pipeline([\n",
       "    ('easypreprocessor', preprocessing.EasyPreprocessor()),\n",
       "    ('simpleregressor', models.SimpleRegressor())\n",
       "])\n",
       "\n",
       "# Train the model\n",
       "start_time = time()\n",
       "pipeline.fit(X_train, y_train)\n",
       "training_time = time() - start_time\n",
       "\n",
       "# Make predictions on the test set\n",
       "y_pred = pipeline.predict(X_test)\n",
       "\n",
       "# Calculate evaluation metrics\n",
       "mae = mean_absolute_error(y_test, y_pred)\n",
       "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
       "rae = mae / y_test.mean()\n",
       "rrse = rmse / y_test.var()\n",
       "\n",
       "# Output evaluation metrics and training time\n",
       "print(f\"Mean Absolute Error: {mae}\")\n",
       "print(f\"Root Mean Squared Error: {rmse}\")\n",
       "print(f\"Relative Absolute Error: {rae}\")\n",
       "print(f\"Root Relative Squared Error: {rrse}\")\n",
       "print(f\"Training time: {training_time} seconds\")\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Create a complete Python script for a regression task using scikit-learn and dabl, utilizing the following pipeline:\n",
    "\n",
    "Pipeline:\n",
    "\n",
    "Preprocessing: dabl.preprocessing.EasyPreprocessor\n",
    "\n",
    "Regressor: dabl.models.SimpleRegressor\n",
    "\n",
    "Use the default hyperparameters as shown in the following AutoML-recommended example:\n",
    "\n",
    "sklearn.pipeline.Pipeline(\n",
    "    steps=[\n",
    "        ('easypreprocessor', dabl.preprocessing.EasyPreprocessor()),\n",
    "        ('simpleregressor', dabl.models.SimpleRegressor())\n",
    "    ],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "Make sure the following Python dependencies are installed:\n",
    "scikit-learn, dabl, pandas\n",
    "\n",
    "Use the dataset scratchtest_transformed.csv with the following structure (first rows):\n",
    "\n",
    "run_id,trial_id,experiment_id,x_position,x_force,y_force,z_force,index,label  \n",
    "0.0,0.0,0.0,20.000118762255,-0.0035452656447887,-0.029228178784251,1.6382834911346,0,344  \n",
    "0.0,0.0,0.0,20.000118762255,0.0043591051362455,-0.026274267584085,2.8769311904907,1,344  \n",
    "0.0,0.0,0.0,20.00012807548,0.0059745712205768,-0.046690504997969,3.2621204853058,2,344  \n",
    "\n",
    "The target variable is the label column. Use all other numerical columns as features.\n",
    "\n",
    "Load the data as a Pandas DataFrame, split it into training and test sets, train the model, and output the following evaluation metrics on the test set:\n",
    "\n",
    "Mean Absolute Error (MAE)\n",
    "\n",
    "Relative Absolute Error (RAE)\n",
    "\n",
    "Root Mean Squared Error (RMSE)\n",
    "\n",
    "Root Relative Squared Error (RRSE)\n",
    "\n",
    "Training time\n",
    "\n",
    "Comment the most important steps in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ddd546d-6093-4f03-976d-ae0452874e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DummyRegressor()\n",
      "r2: -0.000 neg_mean_squared_error: -10603.879\n",
      "=== new best DummyRegressor() (using r2):\n",
      "r2: -0.000 neg_mean_squared_error: -10603.879\n",
      "\n",
      "Running DecisionTreeRegressor(max_depth=1)\n",
      "r2: 0.104 neg_mean_squared_error: -9496.160\n",
      "=== new best DecisionTreeRegressor(max_depth=1) (using r2):\n",
      "r2: 0.104 neg_mean_squared_error: -9496.160\n",
      "\n",
      "Running DecisionTreeRegressor(max_leaf_nodes=8)\n",
      "r2: 0.715 neg_mean_squared_error: -3019.874\n",
      "=== new best DecisionTreeRegressor(max_leaf_nodes=8) (using r2):\n",
      "r2: 0.715 neg_mean_squared_error: -3019.874\n",
      "\n",
      "Running DecisionTreeRegressor(max_leaf_nodes=16)\n",
      "r2: 0.890 neg_mean_squared_error: -1163.691\n",
      "=== new best DecisionTreeRegressor(max_leaf_nodes=16) (using r2):\n",
      "r2: 0.890 neg_mean_squared_error: -1163.691\n",
      "\n",
      "Running DecisionTreeRegressor(max_leaf_nodes=32)\n",
      "r2: 0.959 neg_mean_squared_error: -430.453\n",
      "=== new best DecisionTreeRegressor(max_leaf_nodes=32) (using r2):\n",
      "r2: 0.959 neg_mean_squared_error: -430.453\n",
      "\n",
      "Running DecisionTreeRegressor(max_depth=5)\n",
      "r2: 0.828 neg_mean_squared_error: -1827.271\n",
      "Running Ridge(alpha=10)\n",
      "r2: 0.489 neg_mean_squared_error: -5413.030\n",
      "Running Lasso(alpha=10)\n",
      "r2: 0.083 neg_mean_squared_error: -9722.551\n",
      "\n",
      "Best model:\n",
      "DecisionTreeRegressor(max_leaf_nodes=32)\n",
      "Best Scores:\n",
      "r2: 0.959 neg_mean_squared_error: -430.453\n",
      "Mean Absolute Error: 15.66595381049398\n",
      "Root Mean Squared Error: 20.761461105351373\n",
      "Relative Absolute Error: 0.04599977629331581\n",
      "Root Relative Squared Error: 0.0019560089790152772\n",
      "Training time: 16.33365035057068 seconds\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from dabl import preprocessing, models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./tmp/transformed_data/scratchtest_transformed.csv')\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.drop(['label'], axis=1)\n",
    "y = data['label']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the pipeline consisting of EasyPreprocessor and Simple Regressor\n",
    "pipeline = Pipeline([\n",
    "    ('easypreprocessor', preprocessing.EasyPreprocessor()),\n",
    "    ('simpleregressor', models.SimpleRegressor())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "start_time = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "training_time = time() - start_time\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "rae = mae / y_test.mean()\n",
    "rrse = rmse / y_test.var()\n",
    "\n",
    "# Output evaluation metrics and training time\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"Relative Absolute Error: {rae}\")\n",
    "print(f\"Root Relative Squared Error: {rrse}\")\n",
    "print(f\"Training time: {training_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33ae26-fd00-44bd-ab3b-36f9e8ed6d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (auto-sklearn, py3.9)",
   "language": "python",
   "name": "autosklearn-env39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
